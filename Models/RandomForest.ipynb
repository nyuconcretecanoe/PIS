{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdate\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "aOptimal = pd.read_csv(\"../Trainable data/Anthony/Anthony_Optimal_Training_Data.csv\")\n",
    "aInoptimal = pd.read_csv(\"../Trainable data/Anthony/Anthony_Inoptimal_Training_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "row0 = aOptimal.iloc[0].values.tolist()[1:]\n",
    "\n",
    "xarr = []\n",
    "yarr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 1\n",
    "while (u < aOptimal.shape[0]):\n",
    "    \n",
    "    row0 = aOptimal.iloc[u].values.tolist()[1:]\n",
    "    \n",
    "    rfin = []\n",
    "\n",
    "    p = 0\n",
    "    while (p < len(row0)):\n",
    "\n",
    "        row0[p] = row0[p][1:-1]\n",
    "        row0[p] = row0[p].split(\",\")\n",
    "\n",
    "        k = 0\n",
    "        while (k < len(row0[p]) and k < 155):\n",
    "            # effectively flatten it\n",
    "#             row0[p][k] = float(row0[p][k])\n",
    "            rfin.append(float(row0[p][k]))\n",
    "            k += 1\n",
    "        \n",
    "        # print the length of features in that stroke\n",
    "        # print(k)\n",
    "\n",
    "        p += 1\n",
    "    \n",
    "    u += 1\n",
    "    \n",
    "    xarr.append(rfin)\n",
    "    yarr.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 0\n",
    "while (u < aInoptimal.shape[0]):\n",
    "    \n",
    "    row0 = aInoptimal.iloc[u].values.tolist()[1:]\n",
    "    \n",
    "    rfin = []\n",
    "\n",
    "    p = 0\n",
    "    while (p < len(row0)):\n",
    "\n",
    "        row0[p] = row0[p][1:-1]\n",
    "        row0[p] = row0[p].split(\",\")\n",
    "\n",
    "        k = 0\n",
    "        while (k < len(row0[p]) and k < 155):\n",
    "            # effectively flatten it\n",
    "#             row0[p][k] = float(row0[p][k])\n",
    "            rfin.append(float(row0[p][k]))\n",
    "            k += 1\n",
    "        \n",
    "        # print the length of features in that stroke\n",
    "        # print(k)\n",
    "\n",
    "        p += 1\n",
    "    \n",
    "    u += 1\n",
    "    \n",
    "    xarr.append(rfin)\n",
    "    yarr.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.75451660e-02,  6.88018799e-02,  8.31909180e-02, ...,\n",
       "         1.37641327e+02,  1.37967133e+02,  1.37851166e+02],\n",
       "       [-3.88793945e-02, -2.21099853e-02, -2.49328613e-02, ...,\n",
       "         1.38776810e+02,  1.38790558e+02,  1.38839233e+02],\n",
       "       [-7.92236328e-02, -7.52563477e-02, -4.37316894e-02, ...,\n",
       "         1.38367050e+02,  1.38225815e+02,  1.38413101e+02],\n",
       "       ...,\n",
       "       [ 2.70065308e-01,  2.69958496e-01,  2.66098022e-01, ...,\n",
       "         1.59204590e+02,  1.59235763e+02,  1.59317444e+02],\n",
       "       [-1.02966309e-01, -1.18484497e-01, -1.43173218e-01, ...,\n",
       "         1.60044815e+02,  1.59853882e+02,  1.59837357e+02],\n",
       "       [ 2.09487915e-01,  2.16323852e-01,  2.24975586e-01, ...,\n",
       "         1.55824158e+02,  1.55920593e+02,  1.56143082e+02]],\n",
       "      shape=(52, 2790))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(xarr)\n",
    "y = np.array(yarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\n",
    "    X, y, test_size=0.33, random_state=random.randint(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = make_pipeline(StandardScaler(), RandomForestClassifier(class_weight='balanced'))\n",
    "\n",
    "RF_model.fit(X_train, y_train)\n",
    "\n",
    "predict_y = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "i = 0\n",
    "while (i < len(predict_y)):\n",
    "    pred = predict_y[i]\n",
    "    real = y_test[i]\n",
    "    \n",
    "    if (pred == real and pred == 1):\n",
    "        true_pos += 1\n",
    "    elif (pred == real and pred == 0):\n",
    "        true_neg += 1\n",
    "    elif (pred != real and real == 0):\n",
    "        false_pos += 1\n",
    "    else:\n",
    "        false_neg += 1\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "precision = (true_pos)/(true_pos+false_pos)\n",
    "recall = (true_pos)/(true_pos+false_neg)\n",
    "accuracy = (true_pos+true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "fscore = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True labels: [0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\", predict_y)\n",
    "print(\"True labels:\", y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CanoeModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
