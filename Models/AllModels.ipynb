{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdate\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "import joblib\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Variance: 3.9659919265559263e+21\n",
      "Bottom 25th Percentile Variance: 0.019274826582954575\n",
      "Mean Variance: 3.96430917814116e+21\n",
      "Bottom 25th Percentile Variance: 0.012590918505227557\n",
      "Mean Variance: 3.965057243447355e+21\n",
      "Bottom 25th Percentile Variance: 0.02760045113752553\n",
      "Removed Features: [2, 3, 4, 5, 6, 24, 25, 30, 31, 33, 39, 47, 53, 55, 56, 57, 63, 65, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 84, 85, 87, 88, 94, 95, 99, 101, 102, 111, 119, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 149, 150, 163, 164, 166, 167, 170, 175, 176, 177, 178, 184, 185, 191, 200, 201, 202, 203, 204, 205, 206, 212, 213, 217, 218, 221, 224, 225, 231, 240, 241, 250, 252, 255, 256, 257, 260, 261, 262, 263, 269, 271, 277, 289, 290, 292, 293, 294, 296, 297, 298, 299, 303, 304, 305, 308, 309, 311, 312, 318, 323, 325, 326, 328, 333]\n",
      "Original shape: (66, 336)\n",
      "New shape after removing: (66, 216)\n",
      "Removed Features: [2, 3, 4, 5, 6, 13, 23, 24, 30, 54, 56, 60, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 86, 89, 92, 93, 97, 99, 100, 101, 116, 123, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 155, 156, 158, 159, 162, 163, 165, 168, 170, 171, 177, 178, 179, 184, 190, 191, 192, 193, 194, 195, 196, 202, 203, 207, 209, 212, 213, 215, 216, 217, 246, 247, 248, 255, 269, 270, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 286, 288, 289, 290, 291, 292, 296, 300, 301, 303, 305]\n",
      "Original shape: (66, 308)\n",
      "New shape after removing correlated features: (66, 203)\n",
      "Removed Features: [2, 3, 4, 5, 6, 12, 20, 34, 35, 43, 50, 51, 58, 59, 60, 66, 67, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 96, 104, 105, 106, 110, 112, 120, 127, 128, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 153, 155, 156, 160, 162, 163, 164, 168, 170, 171, 176, 179, 180, 183, 185, 186, 190, 191, 193, 194, 196, 197, 198, 200, 202, 203, 204, 205, 208, 209, 210, 211, 216, 217, 218, 219, 222, 223, 224, 225, 226, 227, 228, 235, 241, 250, 253, 254, 256, 276, 279, 280, 281, 284, 286, 296, 297, 298, 299, 309, 311, 312, 314, 315, 316, 318, 319, 320, 321, 327, 328, 329, 331, 332, 334, 335, 342, 346, 347, 348, 349, 357]\n",
      "Original shape: (66, 360)\n",
      "New shape after removing correlated features: (66, 221)\n"
     ]
    }
   ],
   "source": [
    "from FeatureAnalysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta is 0.004619\n",
      "delta is 0.000619\n",
      "[378, 151, 247, 151, 151, 178, 172, 190, 188, 190, 195, 189, 212, 187, 193, 227, 169, 194, 210, 198, 213, 203, 206, 212, 204, 213, 208, 225, 208, 222, 212, 230, 230, 220, 216, 217, 225, 231, 216, 209, 207, 216, 214, 151, 664]\n",
      "[-227, 96, -96, 0, 27, -6, 18, -2, 2, 5, -6, 23, -25, 6, 34, -58, 25, 16, -12, 15, -10, 3, 6, -8, 9, -5, 17, -17, 14, -10, 18, 0, -10, -4, 1, 8, 6, -15, -7, -2, 9, -2, -63, 513]\n",
      "[0, 1, 2, 3, 44]\n",
      "[0, 0, 0, 40, 0]\n",
      "delta is 0.0030754\n",
      "delta is 0.0020754\n",
      "[384, 291, 367, 254, 151, 151, 203, 280, 200, 191, 244, 215, 457, 160, 267, 154, 271, 196, 207, 232, 243, 222, 843, 228, 194, 273, 151, 185, 213, 390, 175, 216, 195, 262, 165, 151, 206, 167, 172, 234, 204, 181, 234, 198, 318, 153]\n",
      "[-93, 76, -113, -103, 0, 52, 77, -80, -9, 53, -29, 242, -297, 107, -113, 117, -75, 11, 25, 11, -21, 621, -615, -34, 79, -122, 34, 28, 177, -215, 41, -21, 67, -97, -14, 55, -39, 5, 62, -30, -23, 53, -36, 120, -165]\n",
      "[0, 1, 2, 3, 4, 7, 8, 12, 13, 14, 15, 16, 17, 22, 23, 25, 26, 29, 30, 34, 44, 45]\n",
      "[0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 4, 0, 1, 0, 2, 0, 3, 9, 0, 0]\n",
      "delta is -0.0027882\n",
      "delta is -0.0057882\n",
      "[151, 154, 180, 151, 261, 456, 176, 453, 285, 186, 198, 244, 195, 160, 229, 235, 359, 228, 185, 151, 151, 157, 172, 250, 459, 300, 259, 213, 194, 151, 321, 151, 276, 187, 349, 275, 328, 243, 218, 249, 155, 304, 179, 237, 162, 176, 280, 186, 239, 151, 295, 505]\n",
      "[3, 26, -29, 110, 195, -280, 277, -168, -99, 12, 46, -49, -35, 69, 6, 124, -131, -43, -34, 0, 6, 15, 78, 209, -159, -41, -46, -19, -43, 170, -170, 125, -89, 162, -74, 53, -85, -25, 31, -94, 149, -125, 58, -75, 14, 104, -94, 53, -88, 144, 210]\n",
      "[0, 4, 5, 6, 7, 8, 9, 16, 17, 23, 24, 25, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 44, 46, 47, 49, 50, 51]\n",
      "[3, 0, 0, 0, 0, 0, 6, 0, 5, 0, 0, 4, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "delta is 0.0004387\n",
      "delta is -0.0045613\n",
      "[176, 558, 417, 316, 151, 151, 151, 162, 211, 168, 184, 151, 162, 169, 174, 178, 155, 180, 233, 151, 192, 197, 188, 180, 198, 177, 190, 169, 341, 199, 202, 172, 162, 307, 219, 169, 186, 329, 517, 151, 207, 443, 932, 162, 667, 182, 171, 339, 187, 234, 616, 515, 221, 151, 296, 298, 197, 508, 311, 229, 201, 168, 170, 180, 158, 179, 164, 170, 166, 164, 192, 157, 171, 188, 234, 214, 204, 181, 251, 156, 229, 197, 220, 219, 228, 306, 151, 151]\n",
      "[382, -141, -101, -165, 0, 0, 11, 49, -43, 16, -33, 11, 7, 5, 4, -23, 25, 53, -82, 41, 5, -9, -8, 18, -21, 13, -21, 172, -142, 3, -30, -10, 145, -88, -50, 17, 143, 188, -366, 56, 236, 489, -770, 505, -485, -11, 168, -152, 47, 382, -101, -294, -70, 145, 2, -101, 311, -197, -82, -28, -33, 2, 10, -22, 21, -15, 6, -4, -2, 28, -35, 14, 17, 46, -20, -10, -23, 70, -95, 73, -32, 23, -1, 9, 78, -155, 0]\n",
      "[0, 1, 2, 3, 4, 19, 28, 29, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 78, 79, 80, 85, 86]\n",
      "[0, 0, 0, 0, 14, 8, 0, 3, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 18, 0, 0, 4, 0, 1]\n",
      "delta is -0.0075467\n",
      "delta is -0.0085467\n",
      "[151, 318, 479, 176, 176, 178, 192, 187, 187, 188, 211, 236, 259, 151, 178, 193, 190, 192, 195, 186, 205, 202, 198, 194, 202, 198, 211, 208, 215, 209, 196, 220, 220, 223, 220, 231, 151, 188, 580]\n",
      "[167, 161, -303, 0, 2, 14, -5, 0, 1, 23, 25, 23, -108, 27, 15, -3, 2, 3, -9, 19, -3, -4, -4, 8, -4, 13, -3, 7, -6, -13, 24, 0, 3, -3, 11, -80, 37, 392]\n",
      "[0, 1, 2, 3, 13, 36, 38]\n",
      "[0, 0, 0, 9, 22, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(catchcompletearr)\n",
    "y = np.array(catchresultarr)\n",
    "\n",
    "X2 = np.array(pullcompletearr)\n",
    "y2 = np.array(pullresultarr)\n",
    "\n",
    "X3 = np.array(recoverycompletearr)\n",
    "y3 = np.array(recoveryresultarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.7692307692307693 \n",
      "Accuracy: 0.8636363636363636 \n",
      "Fscore: 0.8695652173913044\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf1 = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf1.predict(X_test)\n",
    "predict_y\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.8461538461538461 \n",
      "Accuracy: 0.9090909090909091 \n",
      "Fscore: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf2 = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf2.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero division error\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf3 = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf3.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero division error\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf1 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf1.predict(X_test)\n",
    "predict_y\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.8571428571428571 \n",
      "Accuracy: 0.9545454545454546 \n",
      "Fscore: 0.923076923076923\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf2 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf2.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero division error\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf3 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf3.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.875 \n",
      "Accuracy: 0.9545454545454546 \n",
      "Fscore: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf1 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2')) #penalty prevents overfitting\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf1.predict(X_test)\n",
    "predict_y\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.875 \n",
      "Accuracy: 0.9545454545454546 \n",
      "Fscore: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf2 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2')) #penalty prevents overfitting\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf2.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.875 \n",
      "Accuracy: 0.9545454545454546 \n",
      "Fscore: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf3 = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2')) #penalty prevents overfitting\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf3.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero division error\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf1 = make_pipeline(StandardScaler(), XGBClassifier(n_estimators=100)) \n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf1.predict(X_test)\n",
    "predict_y\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero division error\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf2 = make_pipeline(StandardScaler(), XGBClassifier(n_estimators=100)) \n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf2.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.875 \n",
      "Accuracy: 0.9545454545454546 \n",
      "Fscore: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.33, random_state=random.randint(0, 50))\n",
    "\n",
    "clf3 = make_pipeline(StandardScaler(), XGBClassifier(n_estimators=100)) \n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "predict_y = clf3.predict(X_test)\n",
    "\n",
    "getResults(predict_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73774944e+18,  3.60507967e-06,  9.29481312e+07, ...,\n",
       "         7.34313965e-01, -6.10542297e-01, -2.20668793e-01],\n",
       "       [ 1.73774944e+18,  4.01499878e-06,  1.13298473e+08, ...,\n",
       "         1.04241943e+00, -6.90299988e-01, -2.81784058e-01],\n",
       "       [ 1.73774944e+18,  6.51203180e-06,  9.87631425e+07, ...,\n",
       "         9.00222778e-01, -5.94234467e-01, -1.36581421e-01],\n",
       "       ...,\n",
       "       [ 1.73774977e+18, -3.24646505e-06,  2.35386941e+08, ...,\n",
       "         9.68460083e-01, -6.55563354e-01, -1.27639771e-01],\n",
       "       [ 1.73774977e+18,  1.01621607e-06,  2.09228192e+08, ...,\n",
       "         7.90176392e-01, -4.08485413e-01, -1.56967163e-01],\n",
       "       [ 1.73774978e+18,  8.04025401e-06,  1.48189040e+08, ...,\n",
       "         8.17703247e-01, -5.36857605e-01, -1.44218445e-01]],\n",
       "      shape=(66, 400))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>324</th>\n",
       "      <th>327</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.737749e+18</td>\n",
       "      <td>9.294813e+07</td>\n",
       "      <td>-0.233782</td>\n",
       "      <td>-0.357287</td>\n",
       "      <td>-0.525986</td>\n",
       "      <td>-0.008896</td>\n",
       "      <td>0.517090</td>\n",
       "      <td>-0.285793</td>\n",
       "      <td>-0.116714</td>\n",
       "      <td>-0.139864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411767</td>\n",
       "      <td>-0.043034</td>\n",
       "      <td>-0.786942</td>\n",
       "      <td>-0.554935</td>\n",
       "      <td>-0.432761</td>\n",
       "      <td>-0.040666</td>\n",
       "      <td>-0.812836</td>\n",
       "      <td>-0.078522</td>\n",
       "      <td>-0.610542</td>\n",
       "      <td>-0.220669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.737749e+18</td>\n",
       "      <td>1.132985e+08</td>\n",
       "      <td>-0.259065</td>\n",
       "      <td>0.428777</td>\n",
       "      <td>-0.522812</td>\n",
       "      <td>0.071976</td>\n",
       "      <td>0.594788</td>\n",
       "      <td>-0.365852</td>\n",
       "      <td>-0.183884</td>\n",
       "      <td>-0.480386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455642</td>\n",
       "      <td>0.167781</td>\n",
       "      <td>-0.883942</td>\n",
       "      <td>-0.747322</td>\n",
       "      <td>-0.516359</td>\n",
       "      <td>-0.277641</td>\n",
       "      <td>-1.139481</td>\n",
       "      <td>-0.097061</td>\n",
       "      <td>-0.690300</td>\n",
       "      <td>-0.281784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.737749e+18</td>\n",
       "      <td>9.876314e+07</td>\n",
       "      <td>-0.305130</td>\n",
       "      <td>-0.661243</td>\n",
       "      <td>-0.757217</td>\n",
       "      <td>-0.062912</td>\n",
       "      <td>0.694305</td>\n",
       "      <td>-0.413692</td>\n",
       "      <td>-0.170509</td>\n",
       "      <td>0.237682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.553583</td>\n",
       "      <td>-0.008241</td>\n",
       "      <td>-1.068573</td>\n",
       "      <td>-0.818531</td>\n",
       "      <td>-0.358277</td>\n",
       "      <td>-0.080598</td>\n",
       "      <td>-0.831253</td>\n",
       "      <td>0.068970</td>\n",
       "      <td>-0.594234</td>\n",
       "      <td>-0.136581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.737749e+18</td>\n",
       "      <td>1.045778e+08</td>\n",
       "      <td>-0.333538</td>\n",
       "      <td>-0.466570</td>\n",
       "      <td>-0.814026</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.820908</td>\n",
       "      <td>-0.434467</td>\n",
       "      <td>-0.161812</td>\n",
       "      <td>-1.187938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629914</td>\n",
       "      <td>-0.337569</td>\n",
       "      <td>-1.013992</td>\n",
       "      <td>-0.768036</td>\n",
       "      <td>-0.255113</td>\n",
       "      <td>-0.351017</td>\n",
       "      <td>-0.692963</td>\n",
       "      <td>0.064850</td>\n",
       "      <td>-0.434475</td>\n",
       "      <td>-0.048515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.737749e+18</td>\n",
       "      <td>1.365544e+08</td>\n",
       "      <td>-0.366561</td>\n",
       "      <td>-0.531791</td>\n",
       "      <td>-0.837418</td>\n",
       "      <td>-0.014603</td>\n",
       "      <td>0.822815</td>\n",
       "      <td>-0.437881</td>\n",
       "      <td>-0.261024</td>\n",
       "      <td>-0.317249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603084</td>\n",
       "      <td>0.310328</td>\n",
       "      <td>-1.110748</td>\n",
       "      <td>-0.815842</td>\n",
       "      <td>-0.449815</td>\n",
       "      <td>-0.049849</td>\n",
       "      <td>-0.905930</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>-0.623528</td>\n",
       "      <td>-0.231262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1         7         8         9         10   \\\n",
       "0  1.737749e+18  9.294813e+07 -0.233782 -0.357287 -0.525986 -0.008896   \n",
       "1  1.737749e+18  1.132985e+08 -0.259065  0.428777 -0.522812  0.071976   \n",
       "2  1.737749e+18  9.876314e+07 -0.305130 -0.661243 -0.757217 -0.062912   \n",
       "3  1.737749e+18  1.045778e+08 -0.333538 -0.466570 -0.814026  0.006882   \n",
       "4  1.737749e+18  1.365544e+08 -0.366561 -0.531791 -0.837418 -0.014603   \n",
       "\n",
       "        11        12        13        14   ...       321       322       324  \\\n",
       "0  0.517090 -0.285793 -0.116714 -0.139864  ... -0.411767 -0.043034 -0.786942   \n",
       "1  0.594788 -0.365852 -0.183884 -0.480386  ... -0.455642  0.167781 -0.883942   \n",
       "2  0.694305 -0.413692 -0.170509  0.237682  ... -0.553583 -0.008241 -1.068573   \n",
       "3  0.820908 -0.434467 -0.161812 -1.187938  ... -0.629914 -0.337569 -1.013992   \n",
       "4  0.822815 -0.437881 -0.261024 -0.317249  ... -0.603084  0.310328 -1.110748   \n",
       "\n",
       "        327       329       330       331       332       334       335  \n",
       "0 -0.554935 -0.432761 -0.040666 -0.812836 -0.078522 -0.610542 -0.220669  \n",
       "1 -0.747322 -0.516359 -0.277641 -1.139481 -0.097061 -0.690300 -0.281784  \n",
       "2 -0.818531 -0.358277 -0.080598 -0.831253  0.068970 -0.594234 -0.136581  \n",
       "3 -0.768036 -0.255113 -0.351017 -0.692963  0.064850 -0.434475 -0.048515  \n",
       "4 -0.815842 -0.449815 -0.049849 -0.905930  0.016510 -0.623528 -0.231262  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fully_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1  1  1  1 -1  1  1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Model Accuracy: 77.27%\n"
     ]
    }
   ],
   "source": [
    "X_fully_reduced_scaled = scaler.transform(X_fully_reduced)\n",
    "X_train = X_fully_reduced_scaled[y == 0]\n",
    "\n",
    "clf1 = OneClassSVM(\n",
    "    gamma='auto', \n",
    "    kernel='rbf', #rbf is best when many dimensions\n",
    "    nu=0.39    # the percent of outliers the model assumes\n",
    "    ).fit(X_train) \n",
    "\n",
    "y_pred_train = clf1.predict(X_fully_reduced_scaled)\n",
    "\n",
    "print(y_pred_train)\n",
    "\n",
    "y_pred_binary = (y_pred_train == -1).astype(int)  # converts -1 to 1\n",
    "accuracy = (y_pred_binary == y).mean()\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Model Accuracy: 77.27%\n"
     ]
    }
   ],
   "source": [
    "scaler2 = StandardScaler()\n",
    "\n",
    "X2_fully_reduced_scaled = scaler2.fit_transform(X2_fully_reduced)\n",
    "X2_train = X2_fully_reduced_scaled[y2 == 0]\n",
    "\n",
    "clf2 = OneClassSVM(\n",
    "    gamma='auto', \n",
    "    kernel='rbf', #rbf is best when many dimensions\n",
    "    nu=0.39    # the percent of outliers the model assumes\n",
    "    ).fit(X2_train) \n",
    "\n",
    "y2_pred_train = clf2.predict(X2_fully_reduced_scaled)\n",
    "\n",
    "print(y2_pred_train)\n",
    "\n",
    "y2_pred_binary = (y2_pred_train == -1).astype(int)  # converts -1 to 1\n",
    "accuracy2 = (y2_pred_binary == y2).mean()\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1  1  1 -1  1  1  1\n",
      "  1  1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Model Accuracy: 77.27%\n"
     ]
    }
   ],
   "source": [
    "scaler3 = StandardScaler()\n",
    "\n",
    "X3_fully_reduced_scaled = scaler3.fit_transform(X3_fully_reduced)\n",
    "X3_train = X3_fully_reduced_scaled[y3 == 0]\n",
    "\n",
    "clf3 = OneClassSVM(\n",
    "    gamma='auto', \n",
    "    kernel='rbf', #rbf is best when many dimensions\n",
    "    nu=0.39    # the percent of outliers the model assumes\n",
    "    ).fit(X3_train) \n",
    "\n",
    "y3_pred_train = clf3.predict(X3_fully_reduced_scaled)\n",
    "\n",
    "print(y3_pred_train)\n",
    "\n",
    "y3_pred_binary = (y3_pred_train == -1).astype(int)  # converts -1 to 1\n",
    "accuracy3 = (y3_pred_binary == y3).mean()\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy3:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Model Accuracy: 75.76%\n"
     ]
    }
   ],
   "source": [
    "clf1 = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    contamination=.4, #percent of outliers\n",
    "    random_state=random.randint(0,50)).fit(X_train)\n",
    "\n",
    "y_pred_train = clf1.predict(X_fully_reduced_scaled)\n",
    "\n",
    "print(y_pred_train)\n",
    "\n",
    "y_pred_binary = (y_pred_train == -1).astype(int)  # converts -1 to 1\n",
    "accuracy = (y_pred_binary == y).mean()\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1 -1  1  1  1 -1 -1 -1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  1  1  1 -1  1 -1 -1 -1 -1  1 -1  1  1 -1  1 -1  1]\n",
      "Model Accuracy: 62.12%\n"
     ]
    }
   ],
   "source": [
    "clf2 = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    contamination=.4, #percent of outliers\n",
    "    random_state=random.randint(0,50)).fit(X2_train)\n",
    "\n",
    "y2_pred_train = clf2.predict(X2_fully_reduced_scaled)\n",
    "\n",
    "print(y2_pred_train)\n",
    "\n",
    "y2_pred_binary = (y2_pred_train == -1).astype(int)  # converts -1 to 1\n",
    "accuracy2 = (y2_pred_binary == y2).mean()\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1  1  1 -1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1\n",
      "  1  1  1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Model Accuracy: 75.76%\n"
     ]
    }
   ],
   "source": [
    "clf3 = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    contamination=.4, #percent of outliers\n",
    "    random_state=random.randint(0,50)).fit(X3_train)\n",
    "\n",
    "y3_pred_train = clf3.predict(X3_fully_reduced_scaled)\n",
    "\n",
    "print(y3_pred_train)\n",
    "\n",
    "y3_pred_binary = (y3_pred_train == -1).astype(int)  # converts -1 to 1\n",
    "accuracy3 = (y3_pred_binary == y3).mean()\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy3:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CanoeModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
