{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta is 0.004619\n",
      "delta is 0.000619\n",
      "[378, 151, 247, 151, 151, 178, 172, 190, 188, 190, 195, 189, 212, 187, 193, 227, 169, 194, 210, 198, 213, 203, 206, 212, 204, 213, 208, 225, 208, 222, 212, 230, 230, 220, 216, 217, 225, 231, 216, 209, 207, 216, 214, 151, 664]\n",
      "[-227, 96, -96, 0, 27, -6, 18, -2, 2, 5, -6, 23, -25, 6, 34, -58, 25, 16, -12, 15, -10, 3, 6, -8, 9, -5, 17, -17, 14, -10, 18, 0, -10, -4, 1, 8, 6, -15, -7, -2, 9, -2, -63, 513]\n",
      "[0, 1, 2, 3, 44]\n",
      "[0, 0, 0, 40, 0]\n",
      "delta is 0.0030754\n",
      "delta is 0.0020754\n",
      "[384, 291, 367, 254, 151, 151, 203, 280, 200, 191, 244, 215, 457, 160, 267, 154, 271, 196, 207, 232, 243, 222, 843, 228, 194, 273, 151, 185, 213, 390, 175, 216, 195, 262, 165, 151, 206, 167, 172, 234, 204, 181, 234, 198, 318, 153]\n",
      "[-93, 76, -113, -103, 0, 52, 77, -80, -9, 53, -29, 242, -297, 107, -113, 117, -75, 11, 25, 11, -21, 621, -615, -34, 79, -122, 34, 28, 177, -215, 41, -21, 67, -97, -14, 55, -39, 5, 62, -30, -23, 53, -36, 120, -165]\n",
      "[0, 1, 2, 3, 4, 7, 8, 12, 13, 14, 15, 16, 17, 22, 23, 25, 26, 29, 30, 34, 44, 45]\n",
      "[0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 4, 0, 1, 0, 2, 0, 3, 9, 0, 0]\n",
      "delta is -0.0027882\n",
      "delta is -0.0057882\n",
      "[151, 154, 180, 151, 261, 456, 176, 453, 285, 186, 198, 244, 195, 160, 229, 235, 359, 228, 185, 151, 151, 157, 172, 250, 459, 300, 259, 213, 194, 151, 321, 151, 276, 187, 349, 275, 328, 243, 218, 249, 155, 304, 179, 237, 162, 176, 280, 186, 239, 151, 295, 505]\n",
      "[3, 26, -29, 110, 195, -280, 277, -168, -99, 12, 46, -49, -35, 69, 6, 124, -131, -43, -34, 0, 6, 15, 78, 209, -159, -41, -46, -19, -43, 170, -170, 125, -89, 162, -74, 53, -85, -25, 31, -94, 149, -125, 58, -75, 14, 104, -94, 53, -88, 144, 210]\n",
      "[0, 4, 5, 6, 7, 8, 9, 16, 17, 23, 24, 25, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 44, 46, 47, 49, 50, 51]\n",
      "[3, 0, 0, 0, 0, 0, 6, 0, 5, 0, 0, 4, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "delta is 0.0004387\n",
      "delta is -0.0045613\n",
      "[176, 558, 417, 316, 151, 151, 151, 162, 211, 168, 184, 151, 162, 169, 174, 178, 155, 180, 233, 151, 192, 197, 188, 180, 198, 177, 190, 169, 341, 199, 202, 172, 162, 307, 219, 169, 186, 329, 517, 151, 207, 443, 932, 162, 667, 182, 171, 339, 187, 234, 616, 515, 221, 151, 296, 298, 197, 508, 311, 229, 201, 168, 170, 180, 158, 179, 164, 170, 166, 164, 192, 157, 171, 188, 234, 214, 204, 181, 251, 156, 229, 197, 220, 219, 228, 306, 151, 151]\n",
      "[382, -141, -101, -165, 0, 0, 11, 49, -43, 16, -33, 11, 7, 5, 4, -23, 25, 53, -82, 41, 5, -9, -8, 18, -21, 13, -21, 172, -142, 3, -30, -10, 145, -88, -50, 17, 143, 188, -366, 56, 236, 489, -770, 505, -485, -11, 168, -152, 47, 382, -101, -294, -70, 145, 2, -101, 311, -197, -82, -28, -33, 2, 10, -22, 21, -15, 6, -4, -2, 28, -35, 14, 17, 46, -20, -10, -23, 70, -95, 73, -32, 23, -1, 9, 78, -155, 0]\n",
      "[0, 1, 2, 3, 4, 19, 28, 29, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 78, 79, 80, 85, 86]\n",
      "[0, 0, 0, 0, 14, 8, 0, 3, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 18, 0, 0, 4, 0, 1]\n",
      "delta is -0.0075467\n",
      "delta is -0.0085467\n",
      "[151, 318, 479, 176, 176, 178, 192, 187, 187, 188, 211, 236, 259, 151, 178, 193, 190, 192, 195, 186, 205, 202, 198, 194, 202, 198, 211, 208, 215, 209, 196, 220, 220, 223, 220, 231, 151, 188, 580]\n",
      "[167, 161, -303, 0, 2, 14, -5, 0, 1, 23, 25, 23, -108, 27, 15, -3, 2, 3, -9, 19, -3, -4, -4, 8, -4, 13, -3, 7, -6, -13, 24, 0, 3, -3, 11, -80, 37, 392]\n",
      "[0, 1, 2, 3, 13, 36, 38]\n",
      "[0, 0, 0, 9, 22, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(catchcompletearr)\n",
    "y = np.array(catchresultarr)\n",
    "\n",
    "X2 = np.array(pullcompletearr)\n",
    "y2 = np.array(pullresultarr)\n",
    "\n",
    "X3 = np.array(recoverycompletearr)\n",
    "y3 = np.array(recoveryresultarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Variance: 3.9659919265559263e+21\n",
      "Bottom 25th Percentile Variance: 0.019274826582954575\n"
     ]
    }
   ],
   "source": [
    "feature_varX = X.var(axis=0)\n",
    "mean_varX = feature_varX.mean()\n",
    "percentile25X = np.percentile(feature_varX, 25)\n",
    "\n",
    "print(f\"Mean Variance: {mean_varX}\")\n",
    "print(f\"Bottom 25th Percentile Variance: {percentile25X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Variance: 3.96430917814116e+21\n",
      "Bottom 25th Percentile Variance: 0.012590918505227557\n"
     ]
    }
   ],
   "source": [
    "feature_varX2 = X2.var(axis=0)\n",
    "mean_varX2 = feature_varX2.mean()\n",
    "percentile25X2 = np.percentile(feature_varX2, 25)\n",
    "\n",
    "print(f\"Mean Variance: {mean_varX2}\")\n",
    "print(f\"Bottom 25th Percentile Variance: {percentile25X2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Variance: 3.965057243447355e+21\n",
      "Bottom 25th Percentile Variance: 0.02760045113752553\n"
     ]
    }
   ],
   "source": [
    "feature_varX3 = X3.var(axis=0)\n",
    "mean_varX3 = feature_varX3.mean()\n",
    "percentile25X3 = np.percentile(feature_varX3, 25)\n",
    "\n",
    "print(f\"Mean Variance: {mean_varX3}\")\n",
    "print(f\"Bottom 25th Percentile Variance: {percentile25X3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Variance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can adjust the threshold but for now I have 0.01. Above there is more data about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reduces features with variance under 1 percent\n",
    "def remove_low_variance(X):\n",
    "    selector = VarianceThreshold(threshold=0.01)\n",
    "    selector.fit(X)\n",
    "    return X[:, selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = remove_low_variance(X)\n",
    "\n",
    "# X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_reduced = remove_low_variance(X2)\n",
    "\n",
    "# X2_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_reduced = remove_low_variance(X3)\n",
    "\n",
    "# X3_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Correlation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_correlation(df, threshold=0.95):\n",
    "\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    # mask to avoid duplicate comparisons and to make sure one of each correlation pair remains\n",
    "    upper_triangle = np.triu(np.ones(corr_matrix.shape), k=1)\n",
    "    \n",
    "    high_corr_pairs = (corr_matrix > threshold) & (upper_triangle == 1)\n",
    "\n",
    "    high_corr_features = [column for column in corr_matrix.columns if any(high_corr_pairs[column])]\n",
    "\n",
    "    df_filtered = df.drop(columns=high_corr_features)\n",
    "\n",
    "    return df_filtered, high_corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.95 # can be adjusted easily\n",
    "\n",
    "X_fully_reduced, removedX = remove_high_correlation(pd.DataFrame(X_reduced), threshold=threshold)\n",
    "X2_fully_reduced, removedX2 = remove_high_correlation(pd.DataFrame(X2_reduced), threshold=threshold)\n",
    "X3_fully_reduced, removedX3 = remove_high_correlation(pd.DataFrame(X3_reduced), threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Features: [2, 3, 4, 5, 6, 24, 25, 30, 31, 33, 39, 47, 53, 55, 56, 57, 63, 65, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 84, 85, 87, 88, 94, 95, 99, 101, 102, 111, 119, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 149, 150, 163, 164, 166, 167, 170, 175, 176, 177, 178, 184, 185, 191, 200, 201, 202, 203, 204, 205, 206, 212, 213, 217, 218, 221, 224, 225, 231, 240, 241, 250, 252, 255, 256, 257, 260, 261, 262, 263, 269, 271, 277, 289, 290, 292, 293, 294, 296, 297, 298, 299, 303, 304, 305, 308, 309, 311, 312, 318, 323, 325, 326, 328, 333]\n",
      "Original shape: (66, 336)\n",
      "New shape after removing correlated features: (66, 216)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removed Features: {removedX}\")\n",
    "print(\"Original shape:\", X_reduced.shape)\n",
    "print(\"New shape after removing:\", X_fully_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Features: [2, 3, 4, 5, 6, 13, 23, 24, 30, 54, 56, 60, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 86, 89, 92, 93, 97, 99, 100, 101, 116, 123, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 155, 156, 158, 159, 162, 163, 165, 168, 170, 171, 177, 178, 179, 184, 190, 191, 192, 193, 194, 195, 196, 202, 203, 207, 209, 212, 213, 215, 216, 217, 246, 247, 248, 255, 269, 270, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 286, 288, 289, 290, 291, 292, 296, 300, 301, 303, 305]\n",
      "Original shape: (66, 308)\n",
      "New shape after removing correlated features: (66, 203)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removed Features: {removedX2}\")\n",
    "print(\"Original shape:\", X2_reduced.shape)\n",
    "print(\"New shape after removing correlated features:\", X2_fully_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Features: [2, 3, 4, 5, 6, 12, 20, 34, 35, 43, 50, 51, 58, 59, 60, 66, 67, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 96, 104, 105, 106, 110, 112, 120, 127, 128, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 153, 155, 156, 160, 162, 163, 164, 168, 170, 171, 176, 179, 180, 183, 185, 186, 190, 191, 193, 194, 196, 197, 198, 200, 202, 203, 204, 205, 208, 209, 210, 211, 216, 217, 218, 219, 222, 223, 224, 225, 226, 227, 228, 235, 241, 250, 253, 254, 256, 276, 279, 280, 281, 284, 286, 296, 297, 298, 299, 309, 311, 312, 314, 315, 316, 318, 319, 320, 321, 327, 328, 329, 331, 332, 334, 335, 342, 346, 347, 348, 349, 357]\n",
      "Original shape: (66, 360)\n",
      "New shape after removing correlated features: (66, 221)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removed Features: {removedX3}\")\n",
    "print(\"Original shape:\", X3_reduced.shape)\n",
    "print(\"New shape after removing correlated features:\", X3_fully_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_matrixX = X_fully_reduced.corr().abs()\n",
    "\n",
    "# mask to avoid duplicates\n",
    "upper_triangleX = np.triu(np.ones(corr_matrixX.shape), k=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CanoeModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
