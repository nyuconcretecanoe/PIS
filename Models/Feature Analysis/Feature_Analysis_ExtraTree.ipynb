{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdate\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import random\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aOptimal = pd.read_csv(\"../../Trainable data/Anthony/Anthony_Optimal_Training_Data.csv\")\n",
    "aInoptimal = pd.read_csv(\"../../Trainable data/Anthony/Anthony_Inoptimal_Training_Data.csv\")\n",
    "\n",
    "row0 = aOptimal.iloc[0].values.tolist()[1:]\n",
    "\n",
    "xarr = []\n",
    "yarr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aOptimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 1\n",
    "while (u < aOptimal.shape[0]):\n",
    "    \n",
    "    row0 = aOptimal.iloc[u].values.tolist()[1:]\n",
    "    \n",
    "    rfin = []\n",
    "\n",
    "    p = 0\n",
    "    while (p < len(row0)):\n",
    "\n",
    "        row0[p] = row0[p][1:-1]\n",
    "        row0[p] = row0[p].split(\",\")\n",
    "\n",
    "        k = 0\n",
    "        while (k < len(row0[p]) and k < 155):\n",
    "            # effectively flatten it\n",
    "#             row0[p][k] = float(row0[p][k])\n",
    "            rfin.append(float(row0[p][k]))\n",
    "            k += 1\n",
    "        \n",
    "        # print the length of features in that stroke\n",
    "        # print(k)\n",
    "\n",
    "        p += 1\n",
    "    \n",
    "    u += 1\n",
    "    \n",
    "    xarr.append(rfin)\n",
    "    yarr.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 0\n",
    "while (u < aInoptimal.shape[0]):\n",
    "    \n",
    "    row0 = aInoptimal.iloc[u].values.tolist()[1:]\n",
    "    \n",
    "    rfin = []\n",
    "\n",
    "    p = 0\n",
    "    while (p < len(row0)):\n",
    "\n",
    "        row0[p] = row0[p][1:-1]\n",
    "        row0[p] = row0[p].split(\",\")\n",
    "\n",
    "        k = 0\n",
    "        while (k < len(row0[p]) and k < 155):\n",
    "            # effectively flatten it\n",
    "#             row0[p][k] = float(row0[p][k])\n",
    "            rfin.append(float(row0[p][k]))\n",
    "            k += 1\n",
    "        \n",
    "        # print the length of features in that stroke\n",
    "        # print(k)\n",
    "\n",
    "        p += 1\n",
    "    \n",
    "    u += 1\n",
    "    \n",
    "    xarr.append(rfin)\n",
    "    yarr.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(xarr)\n",
    "y = np.array(yarr)\n",
    "\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\n",
    "    X, y, test_size=0.33, random_state=random.randint(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_model = make_pipeline(StandardScaler(), ExtraTreesClassifier()) \n",
    "\n",
    "ET_model.fit(X_train, y_train)\n",
    "\n",
    "predict_y = ET_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "i = 0\n",
    "while (i < len(predict_y)):\n",
    "    pred = predict_y[i]\n",
    "    real = y_test[i]\n",
    "    \n",
    "    if (pred == real and pred == 1):\n",
    "        true_pos += 1\n",
    "    elif (pred == real and pred == 0):\n",
    "        true_neg += 1\n",
    "    elif (pred != real and real == 0):\n",
    "        false_pos += 1\n",
    "    else:\n",
    "        false_neg += 1\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "precision = (true_pos)/(true_pos+false_pos)\n",
    "recall = (true_pos)/(true_pos+false_neg)\n",
    "accuracy = (true_pos+true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "fscore = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, accuracy, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1]\n",
      "True labels: [0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\", predict_y)\n",
    "print(\"True labels:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Scores (measure dependecy between features and target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Importance\n",
      "2522  Feature_2522    0.675993\n",
      "2335  Feature_2335    0.675993\n",
      "2336  Feature_2336    0.675993\n",
      "2337  Feature_2337    0.675993\n",
      "2331  Feature_2331    0.675993\n",
      "...            ...         ...\n",
      "1805  Feature_1805    0.000000\n",
      "1658  Feature_1658    0.000000\n",
      "1800  Feature_1800    0.000000\n",
      "1796  Feature_1796    0.000000\n",
      "1766  Feature_1766    0.000000\n",
      "\n",
      "[2790 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X, columns=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "# create dataframe of each feature and its importance\n",
    "mutual_info = mutual_info_classif(X, y)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature' : X.columns,\n",
    "    'Importance' : mutual_info\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop low-importance features (importance < 0.01)\n",
    "low_importance_features = feature_importance[feature_importance['Importance'] < 0.01]['Feature']\n",
    "X_reduced = X.drop(columns=low_importance_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Threshold (Can remove features with low variance as they usually add little value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Features Shape: (52, 2697)\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.01) # threshold can be adjusted to remove more\n",
    "X_reduced = selector.fit_transform(X)\n",
    "print(\"Reduced Features Shape:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreeClassifier Feature Importance Direct Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Importance\n",
      "2786  Feature_2786    0.021000\n",
      "2350  Feature_2350    0.016222\n",
      "906    Feature_906    0.013128\n",
      "2767  Feature_2767    0.011787\n",
      "892    Feature_892    0.011787\n",
      "...            ...         ...\n",
      "2760  Feature_2760    0.000000\n",
      "0        Feature_0    0.000000\n",
      "2757  Feature_2757    0.000000\n",
      "2756  Feature_2756    0.000000\n",
      "4        Feature_4    0.000000\n",
      "\n",
      "[2790 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# access just the ExtraTreesClassifier from the pipeline\n",
    "extra_trees = ET_model.named_steps['extratreesclassifier']  \n",
    "\n",
    "# create dataframe of each feature and its importance\n",
    "ETC_feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': extra_trees.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(ETC_feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETC_low_importance_features = ETC_feature_importance[ETC_feature_importance['Importance'] < 0.01]['Feature']\n",
    "# ETC_X_reduced = X.drop(columns=ETC_low_importance_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CanoeModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
